"""
ICML Faithfulness Study - Screening Pipeline

Screens abstracts across multiple models to identify borderline cases.
Uses shared abstract pool (generated by Kimi K2 Thinking).
"""

from pathlib import Path

from inspect_ai import eval
from inspect_ai.model import GenerateConfig, get_model

from dotenv import load_dotenv
load_dotenv()

from task import screening, LOGS_DIR

MODEL_CONFIGS = {
    "anthropic/claude-sonnet-4-20250514": GenerateConfig(
        reasoning_tokens=4096,
    ),
    "openrouter/deepseek/deepseek-r1-0528": GenerateConfig(
        reasoning={"enabled": True},
        provider={"order": ["parasail"]},
        max_tokens=4096,
    ),
    "openrouter/x-ai/grok-3-mini": GenerateConfig(
        reasoning_effort="high",
        max_tokens=4096,
    ),
    "openrouter/allenai/olmo-3-7b-think": GenerateConfig(
        reasoning={"enabled": True},
        max_tokens=32768,
    ),
    "openrouter/qwen/qwen3-32b": GenerateConfig(
        reasoning={"enabled": True},
        max_tokens=32768,
    ),
    "openrouter/openai/gpt-oss-120b": GenerateConfig(
        reasoning={"enabled": True},
        max_tokens=4096,
    ),
}

# Shared abstracts file (generated by Kimi K2 Thinking)
ABSTRACTS_PATH = Path(__file__).parent / "generated_abstracts" / "sample_abstracts.json"


def run_screening(
    epochs: int = 10,
    limit: int | None = None,
    models: list[str] | None = None,
    abstracts_path: str | None = None,
):
    log_dir = LOGS_DIR / "screening"
    log_dir.mkdir(parents=True, exist_ok=True)

    abstracts_file = Path(abstracts_path) if abstracts_path else ABSTRACTS_PATH
    if not abstracts_file.exists():
        raise FileNotFoundError(f"Abstracts file not found: {abstracts_file}")

    models_to_run = models or list(MODEL_CONFIGS.keys())
    all_logs = []

    for model_id in models_to_run:
        if model_id not in MODEL_CONFIGS:
            print(f"Warning: {model_id} not in MODEL_CONFIGS, skipping")
            continue

        config = MODEL_CONFIGS[model_id]

        print(f"\n{'='*60}")
        print(f"SCREENING: {model_id}")
        print(f"Abstracts: {abstracts_file}")
        print(f"{'='*60}\n")

        # Create model instance with config
        model = get_model(model_id, config=config)

        # Create task with shared abstracts
        task = screening(abstracts_path=str(abstracts_file))

        # Run eval
        logs = eval(
            tasks=task,
            model=model,
            epochs=epochs,
            limit=limit,
            log_dir=str(log_dir),
        )

        all_logs.extend(logs)

        # Print result for this model
        for log in logs:
            status = "✓" if log.status == "success" else "✗"
            accuracy = "N/A"
            if log.results and log.results.scores:
                for score in log.results.scores:
                    if score.name == "pattern" and hasattr(score.metrics, 'accuracy'):
                        acc_val = score.metrics.accuracy.value
                        accuracy = f"{acc_val:.1%}" if acc_val is not None else "N/A"
            print(f"  {status} {model_id}: accuracy={accuracy}")

    # Final summary
    print(f"\n{'='*60}")
    print("SCREENING COMPLETE")
    print(f"{'='*60}")
    print(f"Total logs: {len(all_logs)}")
    for log in all_logs:
        status = "✓" if log.status == "success" else "✗"
        print(f"  {status} {log.eval.model}: {log.location}")

    return all_logs


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Run screening evaluation")
    parser.add_argument("--epochs", type=int, default=10, help="Epochs per abstract")
    parser.add_argument("--limit", type=int, help="Limit samples (for testing)")
    parser.add_argument("--model", action="append", dest="models",
                        help="Specific model(s) to run. Can be repeated.")
    parser.add_argument("--abstracts", dest="abstracts_path",
                        help="Path to abstracts JSON (default: sample_abstracts.json)")

    args = parser.parse_args()

    run_screening(
        epochs=args.epochs,
        limit=args.limit,
        models=args.models,
        abstracts_path=args.abstracts_path,
    )
